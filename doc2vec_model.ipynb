{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0371ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for topic modeling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim import models\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "import re\n",
    "from collections import defaultdict \n",
    "from numpy import dot\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde42262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to SQL database\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "try:\n",
    "    connection = mysql.connector.connect(host='dbnewyorkcartoon.cgyqzvdc98df.us-east-2.rds.amazonaws.com',\n",
    "                                         database='new_york_cartoon',\n",
    "                                         user='dbuser',\n",
    "                                         password='Sql123456')\n",
    "    if connection.is_connected():\n",
    "        db_Info = connection.get_server_info()\n",
    "        print(\"Connected to MySQL Server version \", db_Info)\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"select database();\")\n",
    "        record = cursor.fetchone()\n",
    "        print(\"You succeed to connect to database: \", record)\n",
    "\n",
    "except Error as e:\n",
    "    print(\"Error while connecting to MySQL\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d979c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling down data from SQL database via search\n",
    "sql_select_Query = \"select caption,ranking from result;\"  # you can change query in this line for selecting your target data\n",
    "cursor.execute(sql_select_Query)\n",
    "\n",
    "# show attributes names of target data\n",
    "num_attr = len(cursor.description)\n",
    "attr_names = [i[0] for i in cursor.description]\n",
    "print(attr_names)\n",
    "\n",
    "# get all records\n",
    "records = cursor.fetchall()\n",
    "print(\"Total number of rows in table: \", cursor.rowcount)\n",
    "df = pd.DataFrame(records, columns=attr_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9ff6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unneccessary columns, axis = 1 means to remove vertical axis(columns)\n",
    "df = df.drop(columns=['ranking'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d5117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation lowercasing and creating new column \"caption_processed\"\n",
    "df['caption'] = df['caption'].astype(str)\n",
    "df['caption_processed'] = df['caption'].map(lambda x: re.sub(r'[,\\.\\!\\?\\'\\\"]', '', x).lower())\n",
    "df['caption_processed'] = df['caption_processed'].map(lambda x: re.sub(r'[--]', ' ', x).lower())\n",
    "\n",
    "# Print out the first rows of captions\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318daba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing and clean up text\n",
    "data = df.caption_processed.values.tolist()\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  \n",
    "\n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6112d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold = fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd2507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading stopwords from Spacy\n",
    "en = spacy.load('en_core_web_sm')\n",
    "stop_words = en.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5db6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e9708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51551b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = data_words_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0914e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating document ids\n",
    "def tagged_document(documents):\n",
    "    for i, words in enumerate(documents):\n",
    "        yield gensim.models.doc2vec.TaggedDocument(words, [i])\n",
    "\n",
    "tagged_documents = list(tagged_document(documents))\n",
    "\n",
    "# Print the first TaggedDocument\n",
    "print(tagged_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd814f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, tagged_doc in enumerate(tagged_documents):\n",
    "    # words = tagged_doc.words\n",
    "    # print(f\"Words in Document {i}: {words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1f6362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2Vec model\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size = 200, \n",
    "                                      window = 10,\n",
    "                                      min_count = 5, \n",
    "                                      dm = 1,\n",
    "                                      dbow_words = 0,\n",
    "                                      epochs = 15,\n",
    "                                      workers = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91f5519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model vocabulary\n",
    "model.build_vocab(tagged_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4bf93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "model.train(tagged_documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05417dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the caption vectors to a compressed numpy file\n",
    "def get_document_vectors_with_ids(model, tagged_docs):\n",
    "    document_vectors = []\n",
    "    for i, (doc_id, dv) in enumerate(zip(tagged_docs, model.dv)):\n",
    "        words = doc_id.words\n",
    "        document_vectors.append((f\"Document {i + 1}\", words, dv))\n",
    "    return document_vectors\n",
    "\n",
    "document_vectors_with_ids = get_document_vectors_with_ids(model, tagged_documents)\n",
    "\n",
    "dtype = [('doc_id', 'U20'), ('words', object), ('doc_vector', np.float32, (model.vector_size,))]\n",
    "data = np.array(document_vectors_with_ids, dtype=dtype)\n",
    "\n",
    "# Save the data as an NPZ file\n",
    "np.savez(\"caption_vectors.npz\", data=data)\n",
    "\n",
    "print(\"Document IDs, vectors, and words saved to 'caption_vectors.npz'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
